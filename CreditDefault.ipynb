{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditDefault.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav-sharma-6167/Advanced-ML/blob/main/CreditDefault.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFdMRkf131Pb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM8tAMvv4oZG"
      },
      "source": [
        "df = pd.read_csv('creditdata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "NvujlHGS6KjP",
        "outputId": "6da0d4bc-b241-421d-c902-5b62f26d72c4"
      },
      "source": [
        "df.head()\n",
        "\n",
        "df.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].replace(0,5)\n",
        "df.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].replace(6,5)\n",
        "df['AgeBin'] = pd.cut(df['AGE'],[20, 25, 30, 35, 40, 50, 60, 80])\n",
        "\n",
        "df['LimitBin'] = pd.cut(df['LIMIT_BAL'],[5000, 50000, 100000, 150000, 200000, 300000, 400000, 500000, 1100000])\n",
        "\n",
        "\n",
        "df['PAY_1_new'] = df['PAY_1'].copy()\n",
        "df['PAY_2_new'] = df['PAY_2'].copy()\n",
        "df['PAY_3_new'] = df['PAY_3'].copy()\n",
        "df['PAY_4_new'] = df['PAY_4'].copy()\n",
        "df['PAY_5_new'] = df['PAY_5'].copy()\n",
        "df['PAY_6_new'] = df['PAY_6'].copy()\n",
        "\n",
        "pay_x_new = ['PAY_1_new', 'PAY_2_new', 'PAY_3_new', 'PAY_4_new', 'PAY_5_new', 'PAY_6_new']\n",
        "\n",
        "for col in pay_x_new:  \n",
        "    df.loc[:,col] = df.loc[:,col].replace(5,4)\n",
        "    df.loc[:,col] = df.loc[:,col].replace(6,4)\n",
        "    df.loc[:,col] = df.loc[:,col].replace(7,4)\n",
        "    df.loc[:,col] = df.loc[:,col].replace(8,4)\n",
        "\n",
        "df['BILL_AMT1_bin'] = df['BILL_AMT1'].copy()\n",
        "df['BILL_AMT2_bin'] = df['BILL_AMT2'].copy()\n",
        "df['BILL_AMT3_bin'] = df['BILL_AMT3'].copy()\n",
        "df['BILL_AMT4_bin'] = df['BILL_AMT4'].copy()\n",
        "df['BILL_AMT5_bin'] = df['BILL_AMT5'].copy()\n",
        "df['BILL_AMT6_bin'] = df['BILL_AMT6'].copy()\n",
        "\n",
        "bill_amtx_bins = ['BILL_AMT1_bin', 'BILL_AMT2_bin', 'BILL_AMT3_bin', 'BILL_AMT4_bin', 'BILL_AMT5_bin', 'BILL_AMT6_bin']\n",
        "\n",
        "for i, col in enumerate (bill_amtx_bins):\n",
        "    df[col] = pd.cut(df[bill_amtx_fts[i]],[-350000,-1,0,25000, 75000, 200000, 2000000])\n",
        "    print(df[col].value_counts())\n",
        "\n",
        "df['PAY_AMT1_bin'] = df['PAY_AMT1'].copy()\n",
        "df['PAY_AMT2_bin'] = df['PAY_AMT2'].copy()\n",
        "df['PAY_AMT3_bin'] = df['PAY_AMT3'].copy()\n",
        "df['PAY_AMT4_bin'] = df['PAY_AMT4'].copy()\n",
        "df['PAY_AMT5_bin'] = df['PAY_AMT5'].copy()\n",
        "df['PAY_AMT6_bin'] = df['PAY_AMT6'].copy()\n",
        "\n",
        "pay_amtx_bins = ['PAY_AMT1_bin', 'PAY_AMT2_bin', 'PAY_AMT3_bin', 'PAY_AMT4_bin', 'PAY_AMT5_bin', 'PAY_AMT6_bin']\n",
        "\n",
        "for i, col in enumerate (pay_amtx_bins):\n",
        "    df[col] = pd.cut(df[pay_amtx_fts[i]],[-1, 0, 25000, 50000, 100000, 2000000])\n",
        "    print(df[col].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913</td>\n",
              "      <td>3102</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682</td>\n",
              "      <td>1725</td>\n",
              "      <td>2682</td>\n",
              "      <td>3272</td>\n",
              "      <td>3455</td>\n",
              "      <td>3261</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239</td>\n",
              "      <td>14027</td>\n",
              "      <td>13559</td>\n",
              "      <td>14331</td>\n",
              "      <td>14948</td>\n",
              "      <td>15549</td>\n",
              "      <td>1518</td>\n",
              "      <td>1500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990</td>\n",
              "      <td>48233</td>\n",
              "      <td>49291</td>\n",
              "      <td>28314</td>\n",
              "      <td>28959</td>\n",
              "      <td>29547</td>\n",
              "      <td>2000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1200</td>\n",
              "      <td>1100</td>\n",
              "      <td>1069</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617</td>\n",
              "      <td>5670</td>\n",
              "      <td>35835</td>\n",
              "      <td>20940</td>\n",
              "      <td>19146</td>\n",
              "      <td>19131</td>\n",
              "      <td>2000</td>\n",
              "      <td>36681</td>\n",
              "      <td>10000</td>\n",
              "      <td>9000</td>\n",
              "      <td>689</td>\n",
              "      <td>679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default payment next month\n",
              "0   1      20000    2  ...         0         0                           1\n",
              "1   2     120000    2  ...         0      2000                           1\n",
              "2   3      90000    2  ...      1000      5000                           0\n",
              "3   4      50000    2  ...      1069      1000                           0\n",
              "4   5      50000    1  ...       689       679                           0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0OW4WY8A5l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['default payment next month','ID'],axis=1),df['default payment next month'],test_size = 0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "MmE7Yc1I8GdO",
        "outputId": "682faddf-35ea-4c3f-fd43-b6d9bf461efc"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23879</th>\n",
              "      <td>360000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>2807</td>\n",
              "      <td>894</td>\n",
              "      <td>5939</td>\n",
              "      <td>1390</td>\n",
              "      <td>-5</td>\n",
              "      <td>-5</td>\n",
              "      <td>898</td>\n",
              "      <td>5970</td>\n",
              "      <td>1396</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6478</th>\n",
              "      <td>50000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>7334</td>\n",
              "      <td>7344</td>\n",
              "      <td>5420</td>\n",
              "      <td>4104</td>\n",
              "      <td>1596</td>\n",
              "      <td>1594</td>\n",
              "      <td>2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1596</td>\n",
              "      <td>0</td>\n",
              "      <td>1594</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2842</th>\n",
              "      <td>110000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>10141</td>\n",
              "      <td>11472</td>\n",
              "      <td>12973</td>\n",
              "      <td>12468</td>\n",
              "      <td>13763</td>\n",
              "      <td>13989</td>\n",
              "      <td>1500</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>1500</td>\n",
              "      <td>600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4115</th>\n",
              "      <td>180000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>36484</td>\n",
              "      <td>24049</td>\n",
              "      <td>89271</td>\n",
              "      <td>1946</td>\n",
              "      <td>11859</td>\n",
              "      <td>506</td>\n",
              "      <td>24049</td>\n",
              "      <td>91272</td>\n",
              "      <td>162</td>\n",
              "      <td>11859</td>\n",
              "      <td>506</td>\n",
              "      <td>1304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6655</th>\n",
              "      <td>500000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>4101</td>\n",
              "      <td>11076</td>\n",
              "      <td>3834</td>\n",
              "      <td>-754</td>\n",
              "      <td>6276</td>\n",
              "      <td>16871</td>\n",
              "      <td>11155</td>\n",
              "      <td>4024</td>\n",
              "      <td>754</td>\n",
              "      <td>7030</td>\n",
              "      <td>17050</td>\n",
              "      <td>6063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6\n",
              "23879     360000    1          1  ...         0         0         0\n",
              "6478       50000    1          3  ...         0      1594         0\n",
              "2842      110000    2          2  ...      1500       600         0\n",
              "4115      180000    2          1  ...     11859       506      1304\n",
              "6655      500000    1          2  ...      7030     17050      6063\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98rT1ZF98Ucu",
        "outputId": "a1b36ae1-a621-48b9-f6f7-3dc6c0c842cb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(23)),\n",
        "        layers.Dense(5000, activation=\"relu\"),\n",
        "        layers.Dense(5000, activation=\"relu\"),\n",
        "        layers.Dense(2500, activation=\"relu\"),\n",
        "        layers.Dense(1500, activation=\"relu\"),\n",
        "        layers.Dense(1000, activation=\"relu\"),\n",
        "        layers.Dense(500, activation=\"relu\"),\n",
        "        layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 5000)              120000    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2500)              12502500  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1500)              3751500   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1000)              1501000   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,381,001\n",
            "Trainable params: 43,381,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBF4K8rF8Zc1",
        "outputId": "97cf9c99-0125-4118-871b-09fe8fc6a30b"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, verbose=1,validation_split=0.33,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "421/421 [==============================] - 14s 28ms/step - loss: 112.7756 - acc: 0.6860 - val_loss: 11.3752 - val_acc: 0.3153\n",
            "Epoch 2/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 8.8388 - acc: 0.6940 - val_loss: 8.2324 - val_acc: 0.7581\n",
            "Epoch 3/100\n",
            "421/421 [==============================] - 12s 27ms/step - loss: 3.7752 - acc: 0.7037 - val_loss: 4.6662 - val_acc: 0.7692\n",
            "Epoch 4/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 1.7925 - acc: 0.7198 - val_loss: 1.4797 - val_acc: 0.7730\n",
            "Epoch 5/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 2.2869 - acc: 0.7121 - val_loss: 1.4896 - val_acc: 0.7713\n",
            "Epoch 6/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 1.5813 - acc: 0.7191 - val_loss: 0.7321 - val_acc: 0.7668\n",
            "Epoch 7/100\n",
            "421/421 [==============================] - 11s 27ms/step - loss: 2.7286 - acc: 0.7139 - val_loss: 1.7006 - val_acc: 0.7487\n",
            "Epoch 8/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 1.6899 - acc: 0.7284 - val_loss: 2.3631 - val_acc: 0.2846\n",
            "Epoch 9/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.8364 - acc: 0.7420 - val_loss: 0.7613 - val_acc: 0.7676\n",
            "Epoch 10/100\n",
            "421/421 [==============================] - 12s 27ms/step - loss: 0.6537 - acc: 0.7636 - val_loss: 0.6247 - val_acc: 0.7694\n",
            "Epoch 11/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6184 - acc: 0.7672 - val_loss: 0.6423 - val_acc: 0.7731\n",
            "Epoch 12/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5860 - acc: 0.7735 - val_loss: 0.6718 - val_acc: 0.7731\n",
            "Epoch 13/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6120 - acc: 0.7705 - val_loss: 0.6340 - val_acc: 0.7321\n",
            "Epoch 14/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6959 - acc: 0.7630 - val_loss: 0.6919 - val_acc: 0.7734\n",
            "Epoch 15/100\n",
            "421/421 [==============================] - 12s 27ms/step - loss: 0.6050 - acc: 0.7688 - val_loss: 0.8243 - val_acc: 0.7466\n",
            "Epoch 16/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6523 - acc: 0.7653 - val_loss: 0.5535 - val_acc: 0.7716\n",
            "Epoch 17/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5732 - acc: 0.7742 - val_loss: 1.0177 - val_acc: 0.5819\n",
            "Epoch 18/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5810 - acc: 0.7727 - val_loss: 0.5295 - val_acc: 0.7734\n",
            "Epoch 19/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5474 - acc: 0.7787 - val_loss: 0.6209 - val_acc: 0.7725\n",
            "Epoch 20/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5633 - acc: 0.7753 - val_loss: 0.5329 - val_acc: 0.7716\n",
            "Epoch 21/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5925 - acc: 0.7698 - val_loss: 0.5860 - val_acc: 0.7502\n",
            "Epoch 22/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5469 - acc: 0.7774 - val_loss: 0.5590 - val_acc: 0.7734\n",
            "Epoch 23/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5343 - acc: 0.7773 - val_loss: 0.5413 - val_acc: 0.7697\n",
            "Epoch 24/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6011 - acc: 0.7684 - val_loss: 0.5701 - val_acc: 0.7716\n",
            "Epoch 25/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5562 - acc: 0.7774 - val_loss: 0.5616 - val_acc: 0.7677\n",
            "Epoch 26/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5250 - acc: 0.7791 - val_loss: 0.5165 - val_acc: 0.7734\n",
            "Epoch 27/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.7804 - acc: 0.7597 - val_loss: 0.5495 - val_acc: 0.7686\n",
            "Epoch 28/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6387 - acc: 0.7701 - val_loss: 0.5231 - val_acc: 0.7736\n",
            "Epoch 29/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5364 - acc: 0.7790 - val_loss: 0.5680 - val_acc: 0.7734\n",
            "Epoch 30/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.8498 - acc: 0.7796 - val_loss: 0.5220 - val_acc: 0.7733\n",
            "Epoch 31/100\n",
            "421/421 [==============================] - 12s 27ms/step - loss: 0.5926 - acc: 0.7810 - val_loss: 0.9902 - val_acc: 0.7728\n",
            "Epoch 32/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.6145 - acc: 0.7794 - val_loss: 0.7048 - val_acc: 0.6942\n",
            "Epoch 33/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 1.3160 - acc: 0.7800 - val_loss: 0.5360 - val_acc: 0.7734\n",
            "Epoch 34/100\n",
            "421/421 [==============================] - 12s 28ms/step - loss: 0.5355 - acc: 0.7811 - val_loss: 0.5349 - val_acc: 0.7736\n",
            "Epoch 35/100\n",
            "421/421 [==============================] - 11s 27ms/step - loss: 0.5339 - acc: 0.7810 - val_loss: 0.5350 - val_acc: 0.7736\n",
            "Epoch 36/100\n",
            "421/421 [==============================] - 11s 27ms/step - loss: 0.5828 - acc: 0.7812 - val_loss: 0.5342 - val_acc: 0.7736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Wd0evhFd_TuC",
        "outputId": "2fdf5c2f-af40-4b8c-f69b-6ccb34e7fe0d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btruPwTkBvdx",
        "outputId": "83cc3609-77ee-4e3e-e1b2-faa1b4d2aaa6"
      },
      "source": [
        "model.evaluate(X_train,y_train,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 7ms/step - loss: 0.5289 - acc: 0.7787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5289157032966614, 0.7786567211151123]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yQM_AVOAzUc",
        "outputId": "df7fd513-9723-472c-d0ab-a8eafd35742e"
      },
      "source": [
        "model.evaluate(X_test,y_test,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 1s 9ms/step - loss: 0.5275 - acc: 0.7791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5275251865386963, 0.7790908813476562]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXCDK-pmHo6P",
        "outputId": "ecb50ba3-10d6-49f4-8bad-fa4ec3a890ad"
      },
      "source": [
        "pip install shap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.40.0.tar.gz (371 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 371 kB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.0.0)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.40.0-cp37-cp37m-linux_x86_64.whl size=509254 sha256=2ff5f7c9ee5b192d09d2333a38092a30044e7b3ef7da247b665dfd8571b569bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/35/84/e304841ac4b910bc95fe9a6e5302eb2507b4333728851dcbfb\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "pTOvNDCXHc2Y",
        "outputId": "70fd45c1-96f8-419f-fcf5-e6b1b7e9050e"
      },
      "source": [
        "import shap\n",
        "explainer = shap.DeepExplainer(model , X_test)\n",
        "shap_values = explainer.shap_values(pool)\n",
        "\n",
        "#max_display needed to show more than 20 features\n",
        "shap.summary_plot(shap_values, X_new_train, max_display = len(X_new_train.columns))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2110ad262f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#max_display needed to show more than 20 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheNameYouWant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    223\u001b[0m                          f'found ndim={ndim}')\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n",
            "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\n'tuple' object has no attribute 'rank'\n\nCall arguments received:\n  • inputs=['       LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6\\n12111     180000    2          2  ...     10000      9000      9000\\n23662      70000    2          3  ...      2000      3500       800\\n11449      30000    1          2  ...         0      2500      1840\\n8710      260000    2          3  ...         0         0         0\\n11003      30000    1          2  ...         0         0         0\\n...          ...  ...        ...  ...       ...       ...       ...\\n12091     160000    1          1  ...         0      9596     10284\\n6761      230000    2          2  ...      1004         0      5183\\n28636     380000    2          2  ...      1900         0      3000\\n25035      10000    1          3  ...       199       193       197\\n23413     200000    2          2  ...         0         0         0\\n\\n[9900 rows x 23 columns]']\n  • training=None\n  • mask=None"
          ]
        }
      ]
    }
  ]
}